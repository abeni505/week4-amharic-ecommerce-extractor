{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Pipeline Setup\n",
    "# ==================================\n",
    "# Import SHAP and the Hugging Face pipeline for easy inference.\n",
    "import shap\n",
    "from transformers import pipeline\n",
    "\n",
    "# IMPORTANT: Replace \"abeni505/results\" with your actual Hugging Face model ID.\n",
    "# This loads your fine-tuned model directly from the Hub.\n",
    "model_id = \"abeni505/amharic-ecommerce-ner\"  \n",
    "ner_pipeline = pipeline(\"ner\", model=model_id)\n",
    "\n",
    "print(f\"NER pipeline for model '{model_id}' loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SHAP Explainer\n",
    "# ===============================\n",
    "# SHAP's Explainer for NLP models wraps the pipeline to understand its inputs and outputs.\n",
    "explainer = shap.Explainer(ner_pipeline)\n",
    "\n",
    "# Choose a sample sentence from your data that contains multiple entities.\n",
    "sample_text = \"Original የቆዳ ጫማ ዋጋ 2500 ብር ቦሌ ይገኛል\"\n",
    "print(f\"Explaining predictions for text: '{sample_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and Visualize SHAP values\n",
    "# ===========================================\n",
    "# The explainer calculates SHAP values, which measure the contribution of each token\n",
    "# to the model's final prediction for that token.\n",
    "# This may take a moment to compute.\n",
    "shap_values = explainer([sample_text])\n",
    "\n",
    "print(\"SHAP values calculated. Generating plot...\")\n",
    "# shap.plots.text() creates a visualization where:\n",
    "# - RED words PUSH the model TOWARDS a prediction.\n",
    "# - BLUE words PUSH the model AWAY from a prediction.\n",
    "# The brightness of the color indicates the strength of the push.\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the SHAP Plot\n",
    "# =================================\n",
    "from IPython.display import Markdown\n",
    "\n",
    "### How to Interpret the SHAP Plot\n",
    "\n",
    "The plot above provides a powerful visual explanation of the model's behavior.\n",
    "\n",
    "- **Hover over a word** (e.g., \"2500\"). A dropdown will show the SHAP values for each possible label (`B-PRODUCT`, `I-PRICE`, `O`, etc.).\n",
    "- **Positive (Red) Values:** A high positive SHAP value for a label means the token strongly contributed to the model choosing *that* label. For the word \"2500\", we expect to see a large red value for the `B-PRICE` label.\n",
    "- **Negative (Blue) Values:** A negative SHAP value means the token pushed the model *away* from choosing that label.\n",
    "- **Context is Key:** Notice how the word \"ዋጋ\" (price) might have a positive SHAP value for the `B-PRICE` label on the *next* word (\"2500\"). This shows the model has learned contextual relationships.\n",
    "\n",
    "This technique provides transparency, helping us diagnose model behavior and build trust in its predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week-4-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
