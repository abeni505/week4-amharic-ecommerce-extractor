{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from telethon.sync import TelegramClient\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Allows asyncio to run in a Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Credentials and Define Channels\n",
    "load_dotenv()\n",
    "api_id = int(os.getenv(\"API_ID\"))\n",
    "api_hash = os.getenv(\"API_HASH\")\n",
    "\n",
    "# List of target Telegram channels\n",
    "# UPDATED CHANNEL LIST\n",
    "# It's important to periodically verify these channels are still active and public.\n",
    "channels = [\n",
    "    \"Shageronlinestore\",  # This one still works\n",
    "    \"shegergebya\",  # New - to be verified\n",
    "    \"ethio_brand_collection\",  # New - to be verified\n",
    "    \"ethio_gebeya\",  # New - to be verified\n",
    "    \"ethiopianonlinemarket\",  # New - to be verified\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_messages(channel_name, limit=500):\n",
    "    \"\"\"\n",
    "    Asynchronously connects to a single Telegram channel and scrapes a specified\n",
    "    number of the latest messages.\n",
    "\n",
    "    Args:\n",
    "        channel_name (str): The public username of the Telegram channel (e.g., 'Shageronlinestore').\n",
    "        limit (int): The maximum number of messages to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a message\n",
    "              containing key metadata. Returns an empty list if scraping fails.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store message data for this channel.\n",
    "    all_messages = []\n",
    "\n",
    "    # Establish a connection to Telegram using the Telethon client.\n",
    "    # The 'anon' session name creates a 'anon.session' file for automatic login on subsequent runs.\n",
    "    async with TelegramClient(\"anon\", api_id, api_hash) as client:\n",
    "        print(f\"Fetching messages from '{channel_name}'...\")\n",
    "        try:\n",
    "            # Asynchronously iterate through the messages in the specified channel.\n",
    "            async for message in client.iter_messages(channel_name, limit=limit):\n",
    "                # We only care about messages that contain text content.\n",
    "                if message.text:\n",
    "                    # Append a dictionary with the desired information to our list.\n",
    "                    all_messages.append(\n",
    "                        {\n",
    "                            \"channel\": channel_name,\n",
    "                            \"message_id\": message.id,\n",
    "                            \"text\": message.text,  # The raw text of the post\n",
    "                            \"date\": message.date,  # The timestamp of the post\n",
    "                            \"views\": message.views,  # The view count of the post\n",
    "                        }\n",
    "                    )\n",
    "        except Exception as e:\n",
    "            # Handle potential errors, such as the channel being private or not existing.\n",
    "            print(f\"Error: Could not fetch from '{channel_name}'. Reason: {e}\")\n",
    "\n",
    "    return all_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED AND IMPROVED NORMALIZATION FUNCTION\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_amharic(text):\n",
    "    \"\"\"\n",
    "    Performs comprehensive normalization and cleaning of Amharic and English text\n",
    "    from Telegram posts for NLP tasks.\n",
    "\n",
    "    - Removes URLs\n",
    "    - Removes Telegram-style hashtags and mentions\n",
    "    - Removes emojis and other pictographs\n",
    "    - Normalizes various Amharic punctuation marks to standard Latin equivalents\n",
    "    - Removes repeated punctuation\n",
    "    - Replaces newlines and tabs with a single space\n",
    "    - Strips extra whitespace from the beginning and end\n",
    "    \"\"\"\n",
    "    # 1. Remove URLs\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "    # 2. Remove hashtags and mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    # 3. Remove Emojis and other pictographs/symbols\n",
    "    # This regex pattern covers most emoji ranges, as well as some other symbols.\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001f600-\\U0001f64f\"  # emoticons\n",
    "        \"\\U0001f300-\\U0001f5ff\"  # symbols & pictographs\n",
    "        \"\\U0001f680-\\U0001f6ff\"  # transport & map symbols\n",
    "        \"\\U0001f700-\\U0001f77f\"  # alchemical symbols\n",
    "        \"\\U0001f780-\\U0001f7ff\"  # Geometric Shapes Extended\n",
    "        \"\\U0001f800-\\U0001f8ff\"  # Supplemental Arrows-C\n",
    "        \"\\U0001f900-\\U0001f9ff\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001fa00-\\U0001fa6f\"  # Chess Symbols\n",
    "        \"\\U0001fa70-\\U0001faff\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027b0\"  # Dingbats\n",
    "        \"\\U000024c2-\\U0001f251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # 4. Normalize Amharic punctuation\n",
    "    text = text.replace(\"á¢\", \".\")\n",
    "    text = text.replace(\"á£\", \",\")\n",
    "    text = text.replace(\"á¤\", \";\")\n",
    "    text = text.replace(\"?\", \"?\")\n",
    "\n",
    "    # 5. Normalize visually similar but different characters (if any)\n",
    "    # Example: text = text.replace('á¡', ':') # Uncomment if you find this character\n",
    "\n",
    "    # 6. Remove repeated punctuation and non-essential special characters\n",
    "    text = re.sub(r\"([,.?!;])\\1+\", r\"\\1\", text)  # e.g., '!!!' -> '!'\n",
    "    text = re.sub(\n",
    "        r\"[\\n\\t\\r*â€â€™`â€œâ€]+\", \" \", text\n",
    "    )  # Replace newlines, tabs, special quotes with a space\n",
    "\n",
    "    # 7. Collapse multiple spaces into one and strip leading/trailing whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED main() function\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire data ingestion and preprocessing pipeline.\n",
    "    It scrapes data, cleans it, normalizes it, and returns a processed DataFrame.\n",
    "    \"\"\"\n",
    "    # --- Data Collection ---\n",
    "    all_channel_data = []\n",
    "    for channel in channels:\n",
    "        messages = await fetch_messages(channel)\n",
    "        all_channel_data.extend(messages)\n",
    "        print(f\"Found {len(messages)} messages in '{channel}'.\")\n",
    "\n",
    "    # --- Data Structuring and Cleaning ---\n",
    "\n",
    "    # Convert the list of dictionaries into a pandas DataFrame.\n",
    "    if not all_channel_data:\n",
    "        print(\"No data was collected. Exiting.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if nothing was scraped\n",
    "\n",
    "    df = pd.DataFrame(all_channel_data)\n",
    "    print(f\"\\nCollected a total of {len(df)} messages before cleaning.\")\n",
    "\n",
    "    # --- Comprehensive Preprocessing ---\n",
    "\n",
    "    # Step 1: Drop rows with empty text.\n",
    "    df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "    # Step 2: Apply advanced Amharic normalization.\n",
    "    print(\"Applying advanced Amharic text normalization...\")\n",
    "    df[\"processed_text\"] = df[\"text\"].apply(normalize_amharic)\n",
    "\n",
    "    # Step 3: Remove messages that became empty after normalization.\n",
    "    df = df[df[\"processed_text\"] != \"\"].copy()\n",
    "\n",
    "    # --- Save the Processed Data ---\n",
    "    output_path = \"../data/scraped_telegram_data.csv\"\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nSuccessfully saved {len(df)} cleaned messages to {output_path}\")\n",
    "\n",
    "    # --- Return the final DataFrame ---\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching messages from 'Shageronlinestore'...\n",
      "Found 227 messages in 'Shageronlinestore'.\n",
      "Fetching messages from 'shegergebya'...\n",
      "Found 99 messages in 'shegergebya'.\n",
      "Fetching messages from 'ethio_gebeya_official'...\n",
      "Error: Could not fetch from 'ethio_gebeya_official'. Reason: No user has \"ethio_gebeya_official\" as username\n",
      "Found 0 messages in 'ethio_gebeya_official'.\n",
      "Fetching messages from 'ethio_gebeya'...\n",
      "Found 244 messages in 'ethio_gebeya'.\n",
      "Fetching messages from 'ethiopianonlinemarket'...\n",
      "Found 17 messages in 'ethiopianonlinemarket'.\n",
      "\n",
      "Collected a total of 587 messages before cleaning.\n",
      "Applying advanced Amharic text normalization...\n",
      "\n",
      "Successfully saved 578 cleaned messages to ../data/scraped_telegram_data.csv\n",
      "\n",
      "--- Pipeline Execution Complete. Final DataFrame Head: ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7423</td>\n",
       "      <td>ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2025-06-24 15:47:54+00:00</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7422</td>\n",
       "      <td>ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2025-06-24 15:45:49+00:00</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7421</td>\n",
       "      <td>**â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...</td>\n",
       "      <td>2025-06-24 10:08:29+00:00</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7420</td>\n",
       "      <td>**â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...</td>\n",
       "      <td>2025-06-24 10:08:29+00:00</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7419</td>\n",
       "      <td>ğŸ€3in1 Rotatable outlet extender\\n\\nğŸ‘‰can easily...</td>\n",
       "      <td>2025-06-24 05:36:56+00:00</td>\n",
       "      <td>2593.0</td>\n",
       "      <td>3in1 Rotatable outlet extender can easily conv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel  message_id  \\\n",
       "0  Shageronlinestore        7423   \n",
       "1  Shageronlinestore        7422   \n",
       "2  Shageronlinestore        7421   \n",
       "3  Shageronlinestore        7420   \n",
       "4  Shageronlinestore        7419   \n",
       "\n",
       "                                                text  \\\n",
       "0  ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "1  ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "2  **â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...   \n",
       "3  **â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...   \n",
       "4  ğŸ€3in1 Rotatable outlet extender\\n\\nğŸ‘‰can easily...   \n",
       "\n",
       "                       date   views  \\\n",
       "0 2025-06-24 15:47:54+00:00  1402.0   \n",
       "1 2025-06-24 15:45:49+00:00  1420.0   \n",
       "2 2025-06-24 10:08:29+00:00  2405.0   \n",
       "3 2025-06-24 10:08:29+00:00  2010.0   \n",
       "4 2025-06-24 05:36:56+00:00  2593.0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...  \n",
       "1  5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...  \n",
       "2  Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...  \n",
       "3  Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...  \n",
       "4  3in1 Rotatable outlet extender can easily conv...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- EXECUTE THE PIPELINE ---\n",
    "\n",
    "# Call the main function and store the resulting DataFrame in a variable.\n",
    "# This makes the final data available for inspection in the notebook.\n",
    "processed_df = await main()\n",
    "\n",
    "# Display the first few rows of the final, processed DataFrame to confirm success.\n",
    "print(\"\\n--- Pipeline Execution Complete. Final DataFrame Head: ---\")\n",
    "display(processed_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week-4-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
