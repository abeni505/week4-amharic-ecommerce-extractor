{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from telethon.sync import TelegramClient\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Allows asyncio to run in a Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Credentials and Define Channels\n",
    "load_dotenv()\n",
    "api_id = int(os.getenv('API_ID'))\n",
    "api_hash = os.getenv('API_HASH')\n",
    "\n",
    "# List of target Telegram channels\n",
    "# UPDATED CHANNEL LIST\n",
    "# It's important to periodically verify these channels are still active and public.\n",
    "channels = [\n",
    "    'Shageronlinestore',       # This one still works\n",
    "    'shegergebya',             # New - to be verified\n",
    "    'ethio_brand_collection',  # New - to be verified\n",
    "    'ethio_gebeya',            # New - to be verified\n",
    "    'ethiopianonlinemarket'    # New - to be verified\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_messages(channel_name, limit=500):\n",
    "    \"\"\"\n",
    "    Asynchronously connects to a single Telegram channel and scrapes a specified\n",
    "    number of the latest messages.\n",
    "\n",
    "    Args:\n",
    "        channel_name (str): The public username of the Telegram channel (e.g., 'Shageronlinestore').\n",
    "        limit (int): The maximum number of messages to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a message\n",
    "              containing key metadata. Returns an empty list if scraping fails.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store message data for this channel.\n",
    "    all_messages = []\n",
    "    \n",
    "    # Establish a connection to Telegram using the Telethon client.\n",
    "    # The 'anon' session name creates a 'anon.session' file for automatic login on subsequent runs.\n",
    "    async with TelegramClient('anon', api_id, api_hash) as client:\n",
    "        print(f\"Fetching messages from '{channel_name}'...\")\n",
    "        try:\n",
    "            # Asynchronously iterate through the messages in the specified channel.\n",
    "            async for message in client.iter_messages(channel_name, limit=limit):\n",
    "                # We only care about messages that contain text content.\n",
    "                if message.text:\n",
    "                    # Append a dictionary with the desired information to our list.\n",
    "                    all_messages.append({\n",
    "                        'channel': channel_name,\n",
    "                        'message_id': message.id,\n",
    "                        'text': message.text,         # The raw text of the post\n",
    "                        'date': message.date,         # The timestamp of the post\n",
    "                        'views': message.views        # The view count of the post\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            # Handle potential errors, such as the channel being private or not existing.\n",
    "            print(f\"Error: Could not fetch from '{channel_name}'. Reason: {e}\")\n",
    "            \n",
    "    return all_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED AND IMPROVED NORMALIZATION FUNCTION\n",
    "import re\n",
    "\n",
    "def normalize_amharic(text):\n",
    "    \"\"\"\n",
    "    Performs comprehensive normalization and cleaning of Amharic and English text\n",
    "    from Telegram posts for NLP tasks.\n",
    "\n",
    "    - Removes URLs\n",
    "    - Removes Telegram-style hashtags and mentions\n",
    "    - Removes emojis and other pictographs\n",
    "    - Normalizes various Amharic punctuation marks to standard Latin equivalents\n",
    "    - Removes repeated punctuation\n",
    "    - Replaces newlines and tabs with a single space\n",
    "    - Strips extra whitespace from the beginning and end\n",
    "    \"\"\"\n",
    "    # 1. Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # 2. Remove hashtags and mentions\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 3. Remove Emojis and other pictographs/symbols\n",
    "    # This regex pattern covers most emoji ranges, as well as some other symbols.\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # 4. Normalize Amharic punctuation\n",
    "    text = text.replace('á¢', '.')\n",
    "    text = text.replace('á£', ',')\n",
    "    text = text.replace('á¤', ';')\n",
    "    text = text.replace('?', '?')\n",
    "    \n",
    "    # 5. Normalize visually similar but different characters (if any)\n",
    "    # Example: text = text.replace('á¡', ':') # Uncomment if you find this character\n",
    "    \n",
    "    # 6. Remove repeated punctuation and non-essential special characters\n",
    "    text = re.sub(r'([,.?!;])\\1+', r'\\1', text) # e.g., '!!!' -> '!'\n",
    "    text = re.sub(r'[\\n\\t\\r*â€â€™`â€œâ€]+', ' ', text) # Replace newlines, tabs, special quotes with a space\n",
    "\n",
    "    # 7. Collapse multiple spaces into one and strip leading/trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED main() function\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire data ingestion and preprocessing pipeline.\n",
    "    It scrapes data, cleans it, normalizes it, and returns a processed DataFrame.\n",
    "    \"\"\"\n",
    "    # --- Data Collection ---\n",
    "    all_channel_data = []\n",
    "    for channel in channels:\n",
    "        messages = await fetch_messages(channel)\n",
    "        all_channel_data.extend(messages)\n",
    "        print(f\"Found {len(messages)} messages in '{channel}'.\")\n",
    "\n",
    "    # --- Data Structuring and Cleaning ---\n",
    "\n",
    "    # Convert the list of dictionaries into a pandas DataFrame.\n",
    "    if not all_channel_data:\n",
    "        print(\"No data was collected. Exiting.\")\n",
    "        return pd.DataFrame() # Return an empty DataFrame if nothing was scraped\n",
    "\n",
    "    df = pd.DataFrame(all_channel_data)\n",
    "    print(f\"\\nCollected a total of {len(df)} messages before cleaning.\")\n",
    "\n",
    "    # --- Comprehensive Preprocessing ---\n",
    "\n",
    "    # Step 1: Drop rows with empty text.\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "    # Step 2: Apply advanced Amharic normalization.\n",
    "    print(\"Applying advanced Amharic text normalization...\")\n",
    "    df['processed_text'] = df['text'].apply(normalize_amharic)\n",
    "\n",
    "    # Step 3: Remove messages that became empty after normalization.\n",
    "    df = df[df['processed_text'] != ''].copy()\n",
    "\n",
    "    # --- Save the Processed Data ---\n",
    "    output_path = '../data/scraped_telegram_data.csv'\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nSuccessfully saved {len(df)} cleaned messages to {output_path}\")\n",
    "    \n",
    "    # --- Return the final DataFrame ---\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching messages from 'Shageronlinestore'...\n",
      "Found 227 messages in 'Shageronlinestore'.\n",
      "Fetching messages from 'shegergebya'...\n",
      "Found 99 messages in 'shegergebya'.\n",
      "Fetching messages from 'ethio_brand_collection'...\n",
      "Found 499 messages in 'ethio_brand_collection'.\n",
      "Fetching messages from 'ethio_gebeya'...\n",
      "Found 244 messages in 'ethio_gebeya'.\n",
      "Fetching messages from 'ethiopianonlinemarket'...\n",
      "Found 17 messages in 'ethiopianonlinemarket'.\n",
      "\n",
      "Collected a total of 1086 messages before cleaning.\n",
      "Applying advanced Amharic text normalization...\n",
      "\n",
      "Successfully saved 1077 cleaned messages to ../data/scraped_telegram_data.csv\n",
      "\n",
      "--- Pipeline Execution Complete. Final DataFrame Head: ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7423</td>\n",
       "      <td>ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2025-06-24 15:47:54+00:00</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7422</td>\n",
       "      <td>ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2025-06-24 15:45:49+00:00</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7421</td>\n",
       "      <td>**â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...</td>\n",
       "      <td>2025-06-24 10:08:29+00:00</td>\n",
       "      <td>2407.0</td>\n",
       "      <td>Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7420</td>\n",
       "      <td>**â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...</td>\n",
       "      <td>2025-06-24 10:08:29+00:00</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shageronlinestore</td>\n",
       "      <td>7419</td>\n",
       "      <td>ğŸ€3in1 Rotatable outlet extender\\n\\nğŸ‘‰can easily...</td>\n",
       "      <td>2025-06-24 05:36:56+00:00</td>\n",
       "      <td>2595.0</td>\n",
       "      <td>3in1 Rotatable outlet extender can easily conv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel  message_id  \\\n",
       "0  Shageronlinestore        7423   \n",
       "1  Shageronlinestore        7422   \n",
       "2  Shageronlinestore        7421   \n",
       "3  Shageronlinestore        7420   \n",
       "4  Shageronlinestore        7419   \n",
       "\n",
       "                                                text  \\\n",
       "0  ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "1  ğŸ¥‚5.5L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "2  **â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...   \n",
       "3  **â‡ï¸ Electronic Pest Repeller \\n\\ná‰ áˆ¨áˆ® ğŸ¦—â•á‰¢áŠ•á‰¢ğŸ˜¡â• ...   \n",
       "4  ğŸ€3in1 Rotatable outlet extender\\n\\nğŸ‘‰can easily...   \n",
       "\n",
       "                       date   views  \\\n",
       "0 2025-06-24 15:47:54+00:00  1407.0   \n",
       "1 2025-06-24 15:45:49+00:00  1420.0   \n",
       "2 2025-06-24 10:08:29+00:00  2407.0   \n",
       "3 2025-06-24 10:08:29+00:00  2011.0   \n",
       "4 2025-06-24 05:36:56+00:00  2595.0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...  \n",
       "1  5.5L Glass dispenser jar with Bamboo stand áˆˆá‰°áˆˆ...  \n",
       "2  Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...  \n",
       "3  Electronic Pest Repeller á‰ áˆ¨áˆ® á‰¢áŠ•á‰¢ áŠ á‹­áŒ¥ áˆ¸áˆ¨áˆªá‰µ áŠ¥áŠ“ áˆŒ...  \n",
       "4  3in1 Rotatable outlet extender can easily conv...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- EXECUTE THE PIPELINE ---\n",
    "\n",
    "# Call the main function and store the resulting DataFrame in a variable.\n",
    "# This makes the final data available for inspection in the notebook.\n",
    "processed_df = await main()\n",
    "\n",
    "# Display the first few rows of the final, processed DataFrame to confirm success.\n",
    "print(\"\\n--- Pipeline Execution Complete. Final DataFrame Head: ---\")\n",
    "display(processed_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week-4-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
